#!/usr/bin/env python3
"""
pLIN Classifier â€” Streamlit GUI Application
Plasmid Life Identification Number system with AMRFinderPlus integration.
Run: streamlit run plin_app.py

Copyright (C) 2025 Basil Xavier Britto
Licensed under GPL-3.0 with mandatory citation clause.
See LICENSE and CITATION.cff for details.

CITATION REQUIRED: Any use of this software in publications or derivative
works must cite:
    Xavier, B. (2025). pLIN: A Plasmid Life Identification Number System
    for Hierarchical, Permanent Classification of Bacterial Plasmids
    Integrated with Antimicrobial Resistance Gene Surveillance.
    https://github.com/xavierbasilbritto-hub/pLIN-plasmid-classification
"""

import os
import io
import glob
import hashlib
import tempfile
import subprocess
import zipfile
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import matplotlib.patheffects as pe
from matplotlib.colors import ListedColormap
import plotly.graph_objects as go
import plotly.express as px
from itertools import product as iter_product
from scipy.spatial.distance import pdist, squareform
from scipy.cluster.hierarchy import linkage, fcluster, dendrogram
from Bio import SeqIO
from sklearn.neighbors import KNeighborsClassifier
from collections import Counter

# â”€â”€ Page Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.set_page_config(
    page_title="pLIN Classifier",
    page_icon="ğŸ§¬",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PLIN_THRESHOLDS = {
    "A": 0.150, "B": 0.100, "C": 0.050,
    "D": 0.020, "E": 0.010, "F": 0.001,
}

PLIN_LEVEL_NAMES = {
    "A": "Family", "B": "Subfamily", "C": "Cluster",
    "D": "Subcluster", "E": "Clone", "F": "Strain",
}

ANI_EQUIV = {
    "A": "~85%", "B": "~90%", "C": "~95%",
    "D": "~98%", "E": "~99%", "F": "~99.9%",
}

THRESHOLD_COLORS = {
    "A": "#E53935", "B": "#FB8C00", "C": "#FDD835",
    "D": "#43A047", "E": "#1E88E5", "F": "#8E24AA",
}

STRAIN_COLORS = [
    "#2196F3", "#FF9800", "#4CAF50", "#E91E63", "#9C27B0",
    "#00BCD4", "#FF5722", "#795548", "#607D8B", "#CDDC39",
    "#F44336", "#3F51B5", "#009688", "#FFC107", "#8BC34A",
]

TYPE_COLORS = {"AMR": "#E53935", "STRESS": "#FB8C00", "VIRULENCE": "#8E24AA"}

INC_GROUPS = ["Auto-detect", "IncFII", "IncN", "IncX1", "IncX", "IncH", "Other"]

LINKAGE_METHODS = ["single", "complete", "average", "weighted"]

# Mobility/conjugation marker genes detectable from AMRFinderPlus output
MOBILITY_GENES = {
    "conjugative": {
        "tra": "Transfer (conjugation)",
        "trb": "Transfer (type IV secretion)",
        "vir": "Virulence/T4SS (conjugation-related)",
    },
    "mobilizable": {
        "mob": "Mobilization protein",
        "oriT": "Origin of transfer",
        "nic": "Nickase (relaxase)",
    },
}

# All mobility gene prefixes for scanning
MOBILITY_PREFIXES_CONJUGATIVE = ["traA", "traB", "traC", "traD", "traE", "traF",
                                  "traG", "traH", "traI", "traJ", "traK", "traL",
                                  "traM", "traN", "traP", "traQ", "traR", "traS",
                                  "traT", "traU", "traV", "traW", "traX", "traY",
                                  "trbA", "trbB", "trbC", "trbD", "trbE", "trbF",
                                  "trbG", "trbH", "trbI", "trbJ"]
MOBILITY_PREFIXES_MOBILIZABLE = ["mobA", "mobB", "mobC", "mobD", "mobE", "mobF",
                                  "nikA", "nikB"]

# Paths to precomputed Inc-group classifier data
_APP_DIR = os.path.dirname(os.path.abspath(__file__))
CLASSIFIER_PATH = os.path.join(_APP_DIR, "data", "inc_classifier.npz")
CENTROID_PATH = os.path.join(_APP_DIR, "data", "inc_centroids.npz")

# â”€â”€ Nucleotide Transformer (optional LLM) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

NT_AVAILABLE = False
try:
    import torch as _torch
    from transformers import AutoTokenizer as _AT, AutoModelForMaskedLM as _AM
    NT_AVAILABLE = True
except ImportError:
    pass

NT_MODELS = {
    "NT-v2-50M (Fast)": "InstaDeepAI/nucleotide-transformer-v2-50m-multi-species",
    "NT-v2-100M": "InstaDeepAI/nucleotide-transformer-v2-100m-multi-species",
    "NT-v2-250M": "InstaDeepAI/nucleotide-transformer-v2-250m-multi-species",
    "NT-v2-500M (Best)": "InstaDeepAI/nucleotide-transformer-v2-500m-multi-species",
}
NT_INC_PROBE_PATH = os.path.join(_APP_DIR, "data", "nt_inc_probe.pkl")
NT_AMR_PROBE_PATH = os.path.join(_APP_DIR, "data", "nt_amr_probe.pkl")
NT_CHUNK_SIZE = 5000
NT_STRIDE = 2500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  INC GROUP CLASSIFICATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_resource(show_spinner=False)
def load_inc_classifier():
    """Load precomputed Inc-group KNN classifier (96% CV accuracy)."""
    if os.path.exists(CLASSIFIER_PATH):
        data = np.load(CLASSIFIER_PATH, allow_pickle=True)
        X_train = data["X"]
        y_train = data["y"]
        group_names = [str(g) for g in data["group_names"]]
        knn = KNeighborsClassifier(n_neighbors=5, metric="cosine", weights="distance")
        knn.fit(X_train, y_train)
        return group_names, knn
    elif os.path.exists(CENTROID_PATH):
        data = np.load(CENTROID_PATH, allow_pickle=True)
        group_names = [str(g) for g in data["group_names"]]
        return group_names, data["centroids"]
    return None, None


def _kmer_vector_single(sequence):
    """Compute normalised 4-mer frequency vector for a single sequence."""
    bases = "ACGT"
    all_kmers = ["".join(p) for p in iter_product(bases, repeat=4)]
    kmer_idx = {km: i for i, km in enumerate(all_kmers)}
    seq = sequence.upper()
    counts = np.zeros(256, dtype=np.float64)
    for i in range(len(seq) - 3):
        kmer = seq[i:i + 4]
        if kmer in kmer_idx:
            counts[kmer_idx[kmer]] += 1
    total = counts.sum()
    if total > 0:
        counts /= total
    return counts


def classify_inc_group(sequence, group_names, classifier):
    """Classify a plasmid to its Inc group using KNN or centroid distance.
    Returns (predicted_group, confidence, per_group_probabilities).
    """
    vec = _kmer_vector_single(sequence).reshape(1, -1).astype(np.float32)

    if isinstance(classifier, KNeighborsClassifier):
        proba = classifier.predict_proba(vec)[0]
        pred_idx = np.argmax(proba)
        best_group = group_names[pred_idx]
        confidence = float(proba[pred_idx])
        proba_dict = {group_names[j]: round(float(proba[j]), 4) for j in range(len(group_names))}
        return best_group, confidence, proba_dict
    else:
        # Centroid fallback â€” use cosine similarity as confidence
        centroids = classifier
        v = vec.flatten()
        similarities = {}
        for j, name in enumerate(group_names):
            c = centroids[j]
            norm_a, norm_b = np.linalg.norm(v), np.linalg.norm(c)
            sim = np.dot(v, c) / (norm_a * norm_b) if norm_a > 0 and norm_b > 0 else 0.0
            similarities[name] = round(sim, 4)
        best_group = max(similarities, key=similarities.get)
        return best_group, similarities[best_group], similarities


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ADAPTIVE THRESHOLD CALIBRATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_data(show_spinner=False)
def calibrate_inc_thresholds():
    """Calibrate pLIN thresholds per Inc group from training data distance distributions.

    Uses quantile-based calibration: for each Inc group, compute pairwise cosine
    distances and set thresholds at specific quantile percentiles that correspond
    to the hierarchical levels (Familyâ†’Strain).

    Returns dict: {inc_group: {A: thresh, B: thresh, ...}} or None if no data.
    """
    if not os.path.exists(CLASSIFIER_PATH):
        return None

    data = np.load(CLASSIFIER_PATH, allow_pickle=True)
    X = data["X"]
    y = data["y"]
    group_names = [str(g) for g in data["group_names"]]

    # Quantile percentiles for each pLIN level (from broadest to finest)
    # These correspond to the fraction of within-group distances that should
    # fall below each threshold
    level_quantiles = {
        "A": 0.99,   # Family â€” nearly all within-group distances below this
        "B": 0.95,   # Subfamily
        "C": 0.75,   # Cluster
        "D": 0.50,   # Subcluster â€” median distance
        "E": 0.25,   # Clone
        "F": 0.05,   # Strain â€” only very close pairs
    }

    calibrated = {}
    for i, name in enumerate(group_names):
        mask = y == i
        X_group = X[mask]
        if X_group.shape[0] < 10:
            continue

        # Sample to keep computation tractable
        n = X_group.shape[0]
        if n > 500:
            rng = np.random.default_rng(42)
            idx = rng.choice(n, 500, replace=False)
            X_sub = X_group[idx]
        else:
            X_sub = X_group

        dists = pdist(X_sub.astype(np.float64), metric="cosine")

        thresholds = {}
        for level, q in level_quantiles.items():
            val = float(np.quantile(dists, q))
            # Ensure minimum separation between levels
            thresholds[level] = round(max(val, 0.0005), 6)

        # Ensure monotonic: A > B > C > D > E > F
        levels = list("ABCDEF")
        for j in range(1, len(levels)):
            if thresholds[levels[j]] >= thresholds[levels[j-1]]:
                thresholds[levels[j]] = round(thresholds[levels[j-1]] * 0.7, 6)

        calibrated[name] = thresholds

    return calibrated if calibrated else None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MOBILITY PREDICTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def classify_mobility(amr_df, source_file):
    """Classify plasmid mobility from AMRFinderPlus output.

    Categories:
    - Conjugative: has tra/trb transfer genes (can self-transfer)
    - Mobilizable: has mob genes but no full tra system (needs helper)
    - Non-mobilizable: no detectable transfer/mobilization genes

    Returns (category, genes_found, details).
    """
    if amr_df is None or len(amr_df) == 0:
        return "Unknown", [], "No AMR data"

    sf = source_file.replace(".fasta", "").replace(".fa", "").replace(".fna", "")
    hits = amr_df[amr_df["source_file"] == sf]

    if len(hits) == 0:
        return "Non-mobilizable", [], "No genes detected"

    gene_col = "Element symbol" if "Element symbol" in hits.columns else None
    name_col = "Element name" if "Element name" in hits.columns else None

    if gene_col is None:
        return "Unknown", [], "No gene symbol column"

    all_genes = hits[gene_col].tolist()
    all_names = hits[name_col].tolist() if name_col else []

    # Check for conjugative markers
    conj_found = []
    for gene in all_genes:
        for prefix in MOBILITY_PREFIXES_CONJUGATIVE:
            if gene.startswith(prefix):
                conj_found.append(gene)
                break

    # Also check gene names/descriptions for transfer keywords
    for name in all_names:
        name_lower = str(name).lower()
        if "conjugal transfer" in name_lower or "type iv secretion" in name_lower:
            # Find the corresponding gene
            idx = all_names.index(name)
            g = all_genes[idx]
            if g not in conj_found:
                conj_found.append(g)

    # Check for mobilizable markers
    mob_found = []
    for gene in all_genes:
        for prefix in MOBILITY_PREFIXES_MOBILIZABLE:
            if gene.startswith(prefix):
                mob_found.append(gene)
                break

    if conj_found:
        return "Conjugative", list(set(conj_found)), f"{len(set(conj_found))} transfer gene(s)"
    elif mob_found:
        return "Mobilizable", list(set(mob_found)), f"{len(set(mob_found))} mobilization gene(s)"
    else:
        return "Non-mobilizable", [], "No transfer/mobilization genes detected"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  OUTBREAK / CLONE DETECTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def detect_outbreak_clusters(plin_df, integrated_df):
    """Flag potential outbreak clusters: plasmids sharing same pLIN strain code (F)
    AND identical AMR resistance profile.

    Returns list of dicts with cluster info.
    """
    if integrated_df is None or len(integrated_df) == 0:
        return []

    df = integrated_df.copy()

    # Create AMR fingerprint: sorted set of AMR genes
    if "AMR_genes" in df.columns:
        df["_amr_fingerprint"] = df["AMR_genes"].fillna("").apply(
            lambda x: "|".join(sorted(g.strip() for g in x.split(";") if g.strip()))
        )
    else:
        df["_amr_fingerprint"] = ""

    # Group by strain cluster (bin_F) + AMR fingerprint
    if "bin_F" not in df.columns:
        # Extract from pLIN code
        df["bin_F"] = df["pLIN"].apply(lambda x: x.split(".")[-1] if isinstance(x, str) else "")

    clusters = []
    grouped = df.groupby(["bin_F", "_amr_fingerprint"])
    for (strain_f, amr_fp), group in grouped:
        if len(group) >= 2 and amr_fp:  # At least 2 plasmids with same AMR
            plasmids = group["plasmid_id"].tolist()
            amr_genes = [g.strip() for g in amr_fp.split("|") if g.strip()]
            plin_code = group["pLIN"].iloc[0]
            clusters.append({
                "strain_cluster": int(strain_f) if str(strain_f).isdigit() else strain_f,
                "pLIN": plin_code,
                "n_plasmids": len(group),
                "plasmids": plasmids,
                "amr_genes": amr_genes,
                "n_amr_genes": len(amr_genes),
                "risk_level": "HIGH" if len(amr_genes) >= 3 else "MODERATE",
            })

    # Sort by risk
    clusters.sort(key=lambda c: (-c["n_amr_genes"], -c["n_plasmids"]))
    return clusters


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  NUCLEOTIDE TRANSFORMER (OPTIONAL LLM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@st.cache_resource(show_spinner="Loading Nucleotide Transformer model...")
def load_nt_model(model_name, device_name="cpu"):
    """Load pre-trained Nucleotide Transformer model and tokenizer."""
    import torch
    from transformers import AutoTokenizer, AutoModelForMaskedLM

    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForMaskedLM.from_pretrained(model_name)
    model.eval()
    device = torch.device(device_name)
    model.to(device)
    return tokenizer, model, device


def extract_nt_embedding(sequence, tokenizer, model, device,
                         chunk_size=NT_CHUNK_SIZE, stride=NT_STRIDE):
    """Extract mean-pooled NT embedding for a single plasmid sequence.

    Long sequences are split into overlapping chunks, embedded independently,
    and chunk embeddings are averaged to produce a single vector.
    """
    import torch

    seq = sequence.upper()
    chunks = []
    for start in range(0, len(seq), stride):
        chunk = seq[start:start + chunk_size]
        if len(chunk) < 100:
            continue
        chunks.append(chunk)
    if not chunks:
        chunks = [seq[:chunk_size] if len(seq) >= 100 else seq]

    embeddings = []
    for chunk in chunks:
        tokens = tokenizer(chunk, return_tensors="pt", padding=True,
                           truncation=True, max_length=1000)
        tokens = {k: v.to(device) for k, v in tokens.items()}
        with torch.no_grad():
            outputs = model(**tokens, output_hidden_states=True)
        hidden = outputs.hidden_states[-1]
        mask = tokens["attention_mask"].unsqueeze(-1).float()
        mean_emb = (hidden * mask).sum(dim=1) / mask.sum(dim=1)
        embeddings.append(mean_emb.squeeze().cpu().numpy())

    return np.mean(embeddings, axis=0).astype(np.float32)


def run_nt_predictions(sequences, tokenizer, model, device, progress_cb=None):
    """Extract NT embeddings and run probe predictions for all sequences.

    Returns dict with embeddings, inc predictions, and amr predictions.
    """
    import joblib

    # Extract embeddings
    embeddings = []
    for i, seq in enumerate(sequences):
        emb = extract_nt_embedding(seq, tokenizer, model, device)
        embeddings.append(emb)
        if progress_cb:
            progress_cb((i + 1) / len(sequences))
    X = np.array(embeddings, dtype=np.float32)

    results = {"embeddings": X}

    # Inc group probe
    if os.path.exists(NT_INC_PROBE_PATH):
        probe_data = joblib.load(NT_INC_PROBE_PATH)
        pipeline = probe_data["pipeline"]
        group_names = probe_data["group_names"]
        inc_preds = pipeline.predict(X)
        inc_proba = pipeline.predict_proba(X)
        results["inc_preds"] = [group_names[p] for p in inc_preds]
        results["inc_proba"] = inc_proba
        results["inc_groups"] = group_names
        results["inc_cv_accuracy"] = probe_data.get("cv_accuracy", None)
    else:
        results["inc_preds"] = None

    # AMR class probe
    if os.path.exists(NT_AMR_PROBE_PATH):
        amr_data = joblib.load(NT_AMR_PROBE_PATH)
        amr_pipeline = amr_data["pipeline"]
        amr_classes = amr_data["amr_classes"]
        amr_preds = amr_pipeline.predict(X)
        results["amr_preds"] = amr_preds
        results["amr_classes"] = amr_classes
    else:
        results["amr_preds"] = None

    return results


def detect_nt_device():
    """Auto-detect best available compute device for NT inference."""
    if not NT_AVAILABLE:
        return "cpu"
    import torch
    if torch.cuda.is_available():
        return "cuda"
    if hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
        return "mps"
    return "cpu"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CORE PIPELINE FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def parse_uploaded_fastas(uploaded_files, inc_type):
    """Parse uploaded FASTA files. Auto-detects Inc group when inc_type='Auto-detect'."""
    auto_detect = (inc_type == "Auto-detect")
    group_names, classifier = None, None
    if auto_detect:
        group_names, classifier = load_inc_classifier()
        if group_names is None:
            auto_detect = False
            inc_type = "Unknown"

    records = []
    for uf in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".fasta", mode="wb") as tmp:
            tmp.write(uf.getvalue())
            tmp_path = tmp.name
        try:
            for rec in SeqIO.parse(tmp_path, "fasta"):
                seq = str(rec.seq)
                rec_dict = {
                    "plasmid_id": rec.id,
                    "sequence": seq,
                    "length": len(seq),
                    "source_file": uf.name,
                }
                if auto_detect:
                    detected_inc, confidence, proba = classify_inc_group(seq, group_names, classifier)
                    rec_dict["inc_type"] = detected_inc
                    rec_dict["inc_confidence"] = round(confidence, 4)
                    rec_dict["inc_probabilities"] = proba
                else:
                    rec_dict["inc_type"] = inc_type

                records.append(rec_dict)
        finally:
            os.unlink(tmp_path)
    return records


@st.cache_data(show_spinner=False)
def compute_kmer_vectors(_sequences, k=4):
    """Compute normalised tetranucleotide frequency vectors."""
    bases = "ACGT"
    all_kmers = ["".join(p) for p in iter_product(bases, repeat=k)]
    vectors = np.zeros((len(_sequences), len(all_kmers)), dtype=np.float64)
    for idx, seq in enumerate(_sequences):
        s = seq.upper()
        total = max(len(s) - k + 1, 1)
        for ki, kmer in enumerate(all_kmers):
            vectors[idx, ki] = s.count(kmer) / total
    return vectors


def assign_plin_codes(vectors, linkage_method="single", thresholds=None):
    """Cluster plasmids and assign hierarchical pLIN codes.

    Args:
        vectors: k-mer frequency matrix
        linkage_method: 'single', 'complete', 'average', or 'weighted'
        thresholds: dict {A: val, ...} or None to use defaults
    """
    active_thresholds = thresholds if thresholds else PLIN_THRESHOLDS
    dist_condensed = pdist(vectors, metric="cosine")
    Z = linkage(dist_condensed, method=linkage_method)

    cluster_assignments = {}
    for bname, thresh in active_thresholds.items():
        cluster_assignments[bname] = fcluster(Z, t=thresh, criterion="distance")

    n = vectors.shape[0]
    plin_codes = []
    for i in range(n):
        parts = [str(cluster_assignments[b][i]) for b in active_thresholds]
        plin_codes.append(".".join(parts))

    return plin_codes, cluster_assignments, Z, dist_condensed


def build_results_df(records, plin_codes, cluster_assignments):
    """Build results DataFrame."""
    rows = []
    for i, rec in enumerate(records):
        row = {
            "plasmid_id": rec["plasmid_id"],
            "inc_type": rec["inc_type"],
            "source_file": rec["source_file"],
            "length_bp": rec["length"],
            "pLIN": plin_codes[i],
        }
        if "inc_confidence" in rec:
            row["inc_confidence"] = rec["inc_confidence"]
        for b in PLIN_THRESHOLDS:
            row[f"bin_{b}"] = int(cluster_assignments[b][i])
        rows.append(row)
    return pd.DataFrame(rows)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  AMRFINDERPLUS FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def detect_amrfinder():
    """Auto-detect AMRFinderPlus binary and database."""
    binary = None
    database = None

    # 1. Check PATH
    try:
        result = subprocess.run(["which", "amrfinder"], capture_output=True, text=True)
        if result.returncode == 0 and result.stdout.strip():
            binary = result.stdout.strip()
    except Exception:
        pass

    # 2. Check conda envs
    if not binary:
        home = os.path.expanduser("~")
        search_dirs = [
            os.path.join(home, "miniconda3", "envs"),
            os.path.join(home, "miniforge3", "envs"),
            os.path.join(home, "anaconda3", "envs"),
            os.path.join(home, "mambaforge", "envs"),
        ]
        for base in search_dirs:
            if os.path.isdir(base):
                for env in sorted(os.listdir(base)):
                    candidate = os.path.join(base, env, "bin", "amrfinder")
                    if os.path.isfile(candidate) and os.access(candidate, os.X_OK):
                        binary = candidate
                        break
            if binary:
                break

    # Find database
    if binary:
        prefix = os.path.dirname(os.path.dirname(binary))
        db_base = os.path.join(prefix, "share", "amrfinderplus", "data")
        if os.path.isdir(db_base):
            versions = sorted(
                [d for d in os.listdir(db_base) if d.startswith("20") and os.path.isdir(os.path.join(db_base, d))]
            )
            if versions:
                database = os.path.join(db_base, versions[-1])

    return binary, database


def run_amrfinder_on_files(uploaded_files, binary, database, progress_callback=None):
    """Run AMRFinderPlus on uploaded FASTA files."""
    all_results = []
    total = len(uploaded_files)

    with tempfile.TemporaryDirectory() as tmpdir:
        for idx, uf in enumerate(uploaded_files):
            fasta_path = os.path.join(tmpdir, uf.name)
            with open(fasta_path, "wb") as f:
                f.write(uf.getvalue())

            out_path = os.path.join(tmpdir, f"{uf.name}.amr.tsv")

            cmd = [binary, "-n", fasta_path, "--plus", "-o", out_path]
            if database:
                cmd.extend(["-d", database])

            try:
                subprocess.run(cmd, capture_output=True, timeout=300)
                if os.path.isfile(out_path):
                    df = pd.read_csv(out_path, sep="\t")
                    df.insert(0, "source_file", uf.name.replace(".fasta", "").replace(".fa", "").replace(".fna", ""))
                    all_results.append(df)
            except Exception:
                pass

            if progress_callback:
                progress_callback((idx + 1) / total)

    if all_results:
        return pd.concat(all_results, ignore_index=True)
    return pd.DataFrame()


def integrate_plin_amr(plin_df, amr_df):
    """Integrate pLIN assignments with AMR results."""
    rows = []
    for _, row in plin_df.iterrows():
        sf = row["source_file"].replace(".fasta", "").replace(".fa", "").replace(".fna", "")
        hits = amr_df[amr_df["source_file"] == sf] if len(amr_df) > 0 else pd.DataFrame()

        amr_hits = hits[hits["Type"] == "AMR"] if "Type" in hits.columns and len(hits) > 0 else pd.DataFrame()
        stress_hits = hits[hits["Type"] == "STRESS"] if "Type" in hits.columns and len(hits) > 0 else pd.DataFrame()
        vir_hits = hits[hits["Type"] == "VIRULENCE"] if "Type" in hits.columns and len(hits) > 0 else pd.DataFrame()

        rows.append({
            **row.to_dict(),
            "total_hits": len(hits),
            "AMR_count": len(amr_hits),
            "STRESS_count": len(stress_hits),
            "VIR_count": len(vir_hits),
            "AMR_genes": "; ".join(sorted(amr_hits["Element symbol"].unique())) if len(amr_hits) > 0 else "",
            "STRESS_genes": "; ".join(sorted(stress_hits["Element symbol"].unique())) if len(stress_hits) > 0 else "",
            "AMR_classes": "; ".join(sorted(amr_hits["Class"].unique())) if len(amr_hits) > 0 else "",
        })
    return pd.DataFrame(rows)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  VISUALIZATION FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_strain_cmap(strain_clusters):
    unique_strains = sorted(set(strain_clusters))
    return {s: STRAIN_COLORS[i % len(STRAIN_COLORS)] for i, s in enumerate(unique_strains)}


def fig_to_bytes(fig, fmt="png", dpi=300):
    """Convert matplotlib figure to bytes buffer."""
    buf = io.BytesIO()
    fig.savefig(buf, format=fmt, dpi=dpi, bbox_inches="tight", facecolor="white")
    buf.seek(0)
    return buf.getvalue()


def plot_rectangular_cladogram(Z, labels, plin_codes, strain_clusters):
    strain_cmap = get_strain_cmap(strain_clusters)
    unique_strains = sorted(set(strain_clusters))

    fig, (ax_dendro, ax_plin) = plt.subplots(
        1, 2, figsize=(14, max(8, len(labels) * 0.4)),
        gridspec_kw={"width_ratios": [3, 2], "wspace": 0.02},
    )

    with plt.rc_context({"lines.linewidth": 2.0}):
        ddata = dendrogram(Z, labels=labels, orientation="right",
                           leaf_font_size=9, ax=ax_dendro,
                           color_threshold=0, above_threshold_color="#444444")

    max_merge = Z[:, 2].max()
    ax_dendro.set_xlim(0, max_merge * 1.15)

    leaf_colors = {labels[i]: strain_cmap[sc] for i, sc in enumerate(strain_clusters)}
    for lbl in ax_dendro.get_yticklabels():
        txt = lbl.get_text()
        if txt in leaf_colors:
            lbl.set_color(leaf_colors[txt])
            lbl.set_fontweight("bold")

    for bname, thresh in PLIN_THRESHOLDS.items():
        if thresh <= max_merge * 1.15:
            ax_dendro.axvline(x=thresh, color=THRESHOLD_COLORS[bname],
                              linestyle="--", linewidth=1.2, alpha=0.7)

    offscreen = [(b, t) for b, t in PLIN_THRESHOLDS.items() if t > max_merge * 1.15]
    if offscreen:
        lines = ["Thresholds beyond range:"] + [f"  {b} ({PLIN_LEVEL_NAMES[b]}): d\u2264{t}" for b, t in offscreen]
        ax_dendro.text(0.98, 0.02, "\n".join(lines), transform=ax_dendro.transAxes,
                       fontsize=7, va="bottom", ha="right",
                       bbox=dict(boxstyle="round,pad=0.4", facecolor="lightyellow", alpha=0.9))

    ax_dendro.set_xlabel("Cosine Distance (4-mer)", fontsize=10, fontweight="bold")
    ax_dendro.set_title("Dendrogram", fontsize=11, fontweight="bold")

    ax_plin.set_ylim(ax_dendro.get_ylim())
    ax_plin.set_xlim(0, 1)
    ax_plin.axis("off")
    ax_plin.set_title("pLIN Code", fontsize=11, fontweight="bold")

    leaf_order = ddata["leaves"]
    y_positions = [5 + i * 10 for i in range(len(leaf_order))]
    label_to_plin = dict(zip(labels, plin_codes))
    label_to_strain = dict(zip(labels, strain_clusters))

    for i, leaf_idx in enumerate(leaf_order):
        lbl = labels[leaf_idx]
        color = strain_cmap[label_to_strain[lbl]]
        ax_plin.text(0.05, y_positions[i], label_to_plin[lbl], fontsize=9,
                     fontfamily="monospace", fontweight="bold", color=color, va="center")

    legend_elements = [mpatches.Patch(color=strain_cmap[sc],
                       label=f"Strain {sc} (n={sum(1 for s in strain_clusters if s == sc)})")
                       for sc in unique_strains]
    ax_dendro.legend(handles=legend_elements, title="pLIN Strain (F)",
                     loc="upper right", fontsize=7, title_fontsize=8, framealpha=0.9)

    fig.suptitle(f"pLIN Cladogram (n={len(labels)})", fontsize=13, fontweight="bold", y=0.98)
    return fig


def plot_circular_cladogram(Z, labels, plin_codes, strain_clusters):
    strain_cmap = get_strain_cmap(strain_clusters)
    unique_strains = sorted(set(strain_clusters))
    n = len(labels)

    fig, ax = plt.subplots(figsize=(12, 12), subplot_kw={"polar": True})
    ddata = dendrogram(Z, labels=labels, no_plot=True)
    leaf_order = ddata["leaves"]

    angles = np.linspace(0, 2 * np.pi, n, endpoint=False)
    angle_map = {leaf_order[i]: angles[i] for i in range(n)}

    max_dist = max(Z[:, 2]) * 1.15
    rs = 0.85

    node_pos = {}
    for i in range(n):
        node_pos[i] = (angle_map[i], 0.0)

    for idx, (c1, c2, dist, _) in enumerate(Z):
        c1, c2 = int(c1), int(c2)
        a1, d1 = node_pos[c1]
        a2, d2 = node_pos[c2]
        nid = n + idx
        avg_a = np.arctan2((np.sin(a1) + np.sin(a2)) / 2, (np.cos(a1) + np.cos(a2)) / 2)
        if avg_a < 0: avg_a += 2 * np.pi
        node_pos[nid] = (avg_a, dist)

        for a, d in [(a1, d1), (a2, d2)]:
            ax.plot([a, a], [(1 - d / max_dist) * rs, (1 - dist / max_dist) * rs],
                    color="#555", linewidth=1.5)
        a_min, a_max = min(a1, a2), max(a1, a2)
        arc = np.linspace(a_max, a_min + 2 * np.pi, 50) if (a_max - a_min) > np.pi else np.linspace(a_min, a_max, 50)
        ax.plot(arc, np.full_like(arc, (1 - dist / max_dist) * rs), color="#555", linewidth=1.5)

    for i in range(n):
        a = angle_map[i]
        sc = strain_clusters[i]
        color = strain_cmap[sc]
        ax.scatter(a, rs + 0.02, s=80, c=color, zorder=5, edgecolors="white", linewidth=0.5)
        rot = np.degrees(a) - 90
        ha = "left"
        if 90 < np.degrees(a) < 270:
            rot += 180
            ha = "right"
        ax.text(a, rs + 0.07, f"{labels[i]}  [{plin_codes[i]}]", fontsize=7,
                fontfamily="monospace", fontweight="bold", color=color,
                ha=ha, va="center", rotation=rot, rotation_mode="anchor")

    ax.set_ylim(0, rs + 0.22)
    ax.set_yticks([])
    ax.set_xticks([])
    ax.spines["polar"].set_visible(False)
    ax.grid(False)
    ax.set_title(f"pLIN Circular Cladogram (n={n})", fontsize=13, fontweight="bold", pad=30)

    legend_elements = [mpatches.Patch(color=strain_cmap[sc], label=f"Strain {sc}") for sc in unique_strains]
    ax.legend(handles=legend_elements, title="pLIN Strain (F)", loc="lower left",
              bbox_to_anchor=(-0.05, -0.05), fontsize=7, title_fontsize=8, framealpha=0.9)
    return fig


def plot_cladogram_heatmap(Z, labels, plin_codes, cluster_assignments, records):
    fig = plt.figure(figsize=(16, max(8, len(labels) * 0.4)))
    ax_d = fig.add_axes([0.02, 0.08, 0.25, 0.82])
    ax_h = fig.add_axes([0.30, 0.08, 0.28, 0.82])
    ax_m = fig.add_axes([0.62, 0.08, 0.35, 0.82])

    ddata = dendrogram(Z, labels=labels, orientation="right", leaf_font_size=8,
                       ax=ax_d, color_threshold=0, above_threshold_color="#555")
    max_merge = Z[:, 2].max()
    ax_d.set_xlim(0, max_merge * 1.15)
    for bname, thresh in PLIN_THRESHOLDS.items():
        if thresh <= max_merge * 1.15:
            ax_d.axvline(x=thresh, color=THRESHOLD_COLORS[bname], linestyle="--", linewidth=1, alpha=0.6)
    ax_d.set_xlabel("Cosine Distance", fontsize=9)
    ax_d.set_title("Dendrogram", fontsize=10, fontweight="bold")

    leaf_order = ddata["leaves"]
    bin_labels = list(PLIN_THRESHOLDS.keys())
    heat = np.zeros((len(labels), len(bin_labels)))
    for j, b in enumerate(bin_labels):
        for i, li in enumerate(leaf_order):
            heat[i, j] = cluster_assignments[b][li]

    ax_h.imshow(heat, aspect="auto", cmap="tab20", interpolation="nearest")
    ax_h.set_xticks(range(len(bin_labels)))
    ax_h.set_xticklabels([f"{b}\n({PLIN_LEVEL_NAMES[b]})" for b in bin_labels], fontsize=8)
    ax_h.set_yticks(range(len(labels)))
    ax_h.set_yticklabels([labels[i] for i in leaf_order], fontsize=7)
    for i in range(heat.shape[0]):
        for j in range(heat.shape[1]):
            ax_h.text(j, i, str(int(heat[i, j])), ha="center", va="center", fontsize=7,
                      fontweight="bold", color="white",
                      path_effects=[pe.withStroke(linewidth=2, foreground="black")])
    ax_h.set_title("Cluster Assignments", fontsize=10, fontweight="bold")

    ax_m.axis("off")
    for j, h in enumerate(["Plasmid", "Length (bp)", "pLIN Code"]):
        ax_m.text(j * 0.35, len(labels) + 0.3, h, fontsize=8, fontweight="bold", ha="left")
    ax_m.axhline(y=len(labels), color="black", linewidth=0.8, xmin=0, xmax=0.95)
    for i, li in enumerate(leaf_order):
        y = len(labels) - 1 - i
        ax_m.text(0.0, y, records[li]["source_file"].replace(".fasta", ""), fontsize=7,
                  fontfamily="monospace", ha="left", va="center")
        ax_m.text(0.35, y, f"{records[li]['length']:,}", fontsize=7, ha="left", va="center")
        ax_m.text(0.70, y, plin_codes[li], fontsize=7, fontfamily="monospace",
                  fontweight="bold", color="#1565C0", ha="left", va="center")
    ax_m.set_xlim(-0.05, 1.1)
    ax_m.set_ylim(-1, len(labels) + 1)
    ax_m.set_title("Metadata", fontsize=10, fontweight="bold")

    fig.suptitle(f"pLIN Cladogram + Cluster Assignments (n={len(labels)})",
                 fontsize=13, fontweight="bold", y=0.97)
    return fig


def plot_cladogram_amr(Z, labels, plin_codes, strain_clusters, amr_df, records):
    """Cladogram with AMR gene presence/absence heatmap."""
    strain_cmap = get_strain_cmap(strain_clusters)
    unique_strains = sorted(set(strain_clusters))

    if len(amr_df) == 0:
        return plot_rectangular_cladogram(Z, labels, plin_codes, strain_clusters)

    amr_genes = sorted(amr_df[amr_df["Type"] == "AMR"]["Element symbol"].unique()) if "Type" in amr_df.columns else []
    stress_genes = sorted(amr_df[amr_df["Type"] == "STRESS"]["Element symbol"].unique()) if "Type" in amr_df.columns else []
    gene_list = amr_genes + stress_genes
    gene_types = ["AMR"] * len(amr_genes) + ["STRESS"] * len(stress_genes)

    if not gene_list:
        return plot_rectangular_cladogram(Z, labels, plin_codes, strain_clusters)

    n_genes = len(gene_list)
    n_plasmids = len(labels)
    label_to_source = {labels[i]: records[i]["source_file"].replace(".fasta", "").replace(".fa", "").replace(".fna", "")
                       for i in range(n_plasmids)}

    fig = plt.figure(figsize=(max(18, 12 + n_genes * 0.4), max(10, n_plasmids * 0.45)))
    ax_d = fig.add_axes([0.01, 0.10, 0.16, 0.78])
    ax_p = fig.add_axes([0.18, 0.10, 0.09, 0.78])
    ax_h = fig.add_axes([0.29, 0.10, min(0.50, n_genes * 0.025 + 0.1), 0.78])
    ax_l = fig.add_axes([0.82, 0.10, 0.16, 0.78])

    with plt.rc_context({"lines.linewidth": 2.0}):
        ddata = dendrogram(Z, labels=labels, orientation="right", leaf_font_size=8,
                           ax=ax_d, color_threshold=0, above_threshold_color="#444")
    max_merge = Z[:, 2].max()
    ax_d.set_xlim(0, max_merge * 1.15)
    for bname, thresh in PLIN_THRESHOLDS.items():
        if thresh <= max_merge * 1.15:
            ax_d.axvline(x=thresh, color=THRESHOLD_COLORS[bname], linestyle="--", linewidth=1, alpha=0.6)
    ax_d.set_xlabel("Cosine Distance", fontsize=8)
    ax_d.set_title("Dendrogram", fontsize=9, fontweight="bold")

    leaf_order = ddata["leaves"]
    leaf_colors = {labels[i]: strain_cmap[sc] for i, sc in enumerate(strain_clusters)}
    for lbl in ax_d.get_yticklabels():
        if lbl.get_text() in leaf_colors:
            lbl.set_color(leaf_colors[lbl.get_text()])
            lbl.set_fontweight("bold")

    # pLIN panel
    ax_p.set_ylim(ax_d.get_ylim())
    ax_p.set_xlim(0, 1)
    ax_p.axis("off")
    ax_p.set_title("pLIN", fontsize=9, fontweight="bold")
    y_pos = [5 + i * 10 for i in range(len(leaf_order))]
    label_to_plin = dict(zip(labels, plin_codes))
    label_to_strain = dict(zip(labels, strain_clusters))
    for i, li in enumerate(leaf_order):
        lbl = labels[li]
        ax_p.text(0.05, y_pos[i], label_to_plin[lbl], fontsize=7, fontfamily="monospace",
                  fontweight="bold", color=strain_cmap[label_to_strain[lbl]], va="center")

    # Heatmap
    heat = np.zeros((n_plasmids, n_genes))
    for i, li in enumerate(leaf_order):
        src = label_to_source[labels[li]]
        hits = amr_df[amr_df["source_file"] == src]
        for j, gene in enumerate(gene_list):
            if gene in hits["Element symbol"].values:
                heat[i, j] = 2 if gene_types[j] == "AMR" else 1

    cmap = ListedColormap(["#F5F5F5", "#FFE0B2", "#EF5350"])
    ax_h.imshow(heat, aspect="auto", cmap=cmap, interpolation="nearest", vmin=0, vmax=2)
    ax_h.set_xticks(range(n_genes))
    ax_h.set_xticklabels(gene_list, fontsize=6, rotation=65, ha="left", rotation_mode="anchor")
    for j, tick in enumerate(ax_h.get_xticklabels()):
        tick.set_color(TYPE_COLORS.get(gene_types[j], "#333"))
        tick.set_fontweight("bold")
    ax_h.set_yticks(range(n_plasmids))
    ax_h.set_yticklabels([labels[i] for i in leaf_order], fontsize=7)
    for i in range(heat.shape[0]):
        for j in range(heat.shape[1]):
            if heat[i, j] > 0:
                ax_h.text(j, i, "\u2713", ha="center", va="center", fontsize=6, fontweight="bold",
                          color="white" if heat[i, j] == 2 else "#E65100")
    ax_h.set_xticks(np.arange(-0.5, n_genes), minor=True)
    ax_h.set_yticks(np.arange(-0.5, n_plasmids), minor=True)
    ax_h.grid(which="minor", color="#E0E0E0", linewidth=0.5)
    ax_h.tick_params(which="minor", size=0)
    if amr_genes and stress_genes:
        ax_h.axvline(x=len(amr_genes) - 0.5, color="black", linewidth=2)
    ax_h.set_title("Gene Presence / Absence", fontsize=9, fontweight="bold")

    # Legend
    ax_l.axis("off")
    y = 0.95
    ax_l.text(0.05, y, "Strain Clusters", fontsize=8, fontweight="bold", transform=ax_l.transAxes)
    y -= 0.04
    for sc in unique_strains:
        n = sum(1 for s in strain_clusters if s == sc)
        ax_l.add_patch(mpatches.FancyBboxPatch((0.05, y - 0.01), 0.08, 0.025, transform=ax_l.transAxes,
                       boxstyle="round,pad=0.003", facecolor=strain_cmap[sc], edgecolor="none"))
        ax_l.text(0.16, y + 0.003, f"Strain {sc} (n={n})", fontsize=7,
                  transform=ax_l.transAxes, va="center")
        y -= 0.035

    fig.suptitle(f"pLIN Cladogram with AMR Profile (n={n_plasmids})",
                 fontsize=13, fontweight="bold", y=0.98)
    return fig


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  SESSION STATE INITIALIZATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

for key in ["records", "plin_df", "amr_df", "integrated_df", "Z", "labels",
            "plin_codes", "strain_clusters", "cluster_assignments", "analysis_done",
            "mobility_results", "outbreak_clusters", "active_thresholds",
            "linkage_method_used", "nt_results"]:
    if key not in st.session_state:
        st.session_state[key] = None
if "analysis_done" not in st.session_state:
    st.session_state.analysis_done = False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MAIN HEADER & UPLOAD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

st.title("ğŸ§¬ pLIN Classifier")
st.caption("Plasmid Life Identification Number System â€” Upload FASTA files to begin")

# AMRFinderPlus detection (used in both upload and post-analysis views)
amr_binary, amr_db = detect_amrfinder()

if not st.session_state.analysis_done:
    st.divider()
    upload_col1, upload_col2 = st.columns([2, 1])
    with upload_col1:
        uploaded_files = st.file_uploader(
            "Upload plasmid FASTA files",
            type=["fasta", "fa", "fna"],
            accept_multiple_files=True,
            help="Upload one or more plasmid FASTA files (.fasta, .fa, .fna)",
            key="main_uploader",
        )
    with upload_col2:
        inc_type = st.selectbox(
            "Incompatibility Group",
            INC_GROUPS, index=0,
            help="'Auto-detect' uses a KNN classifier (96% accuracy) trained on 6,346 plasmids to identify Inc group per sequence",
        )
        linkage_method = st.selectbox(
            "Linkage Method",
            LINKAGE_METHODS, index=0,
            help="Single: traditional chaining (default). Complete: max distance, tighter clusters. Average: balanced. Weighted: WPGMA.",
        )
        use_adaptive = st.checkbox(
            "Adaptive thresholds",
            value=False,
            help="Calibrate pLIN thresholds per Inc group from training data distance distributions instead of fixed thresholds",
        )
        if amr_binary:
            run_amr = st.checkbox("Run AMRFinderPlus", value=True)
        else:
            st.warning("AMRFinderPlus not found", icon="âš ï¸")
            run_amr = False

        # Nucleotide Transformer (optional LLM)
        if NT_AVAILABLE:
            use_nt = st.checkbox(
                "Use Nucleotide Transformer (LLM)",
                value=False,
                help="Use a genomic language model for enhanced Inc group and AMR class prediction. Requires trained probes (run train_nt_classifier.py first).",
            )
            if use_nt:
                nt_model_choice = st.selectbox(
                    "NT Model",
                    list(NT_MODELS.keys()), index=0,
                    help="Smaller models are faster; larger models may be more accurate.",
                )
                nt_device = detect_nt_device()
                st.caption(f"Device: {nt_device.upper()}")
            else:
                nt_model_choice = list(NT_MODELS.keys())[0]
                nt_device = "cpu"
        else:
            use_nt = False
            nt_model_choice = None
            nt_device = "cpu"
            st.info("Nucleotide Transformer not available. Install: `pip install transformers torch`", icon="ğŸ¤–")

    if uploaded_files:
        st.info(f"ğŸ“‚ {len(uploaded_files)} file(s) uploaded â€” click **Run Analysis** below.")
        bcol1, bcol2, _ = st.columns([1, 1, 3])
        with bcol1:
            run_btn = st.button("â–¶ Run Analysis", type="primary", use_container_width=True)
        with bcol2:
            if st.button("ğŸ”„ Clear & Reset", use_container_width=True):
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                st.cache_data.clear()
                st.rerun()
    else:
        run_btn = False
        st.markdown("ğŸ‘† **Upload FASTA files above** to get started.")
    st.divider()
else:
    # After analysis â€” show compact controls in main area
    uploaded_files = st.session_state.get("_uploaded_files", None)
    inc_type = st.session_state.get("_inc_type", INC_GROUPS[0])
    linkage_method = st.session_state.get("_linkage_method", "single")
    use_adaptive = st.session_state.get("_use_adaptive", False)
    use_nt = st.session_state.get("_use_nt", False)
    nt_model_choice = st.session_state.get("_nt_model_choice", None)
    nt_device = st.session_state.get("_nt_device", "cpu")
    run_amr = amr_binary is not None
    run_btn = False


# â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with st.sidebar:
    st.title("ğŸ§¬ pLIN")
    st.caption("Plasmid Life Identification Number")
    st.divider()

    if st.session_state.analysis_done:
        st.success("Analysis complete", icon="âœ…")
        df = st.session_state.plin_df
        if df is not None:
            st.metric("Plasmids", len(df))
            st.metric("Unique pLIN Codes", df["pLIN"].nunique())
            if "inc_confidence" in df.columns:
                inc_counts = df["inc_type"].value_counts()
                st.markdown("**Detected Inc Groups:**")
                for inc, cnt in inc_counts.items():
                    st.markdown(f"- {inc}: {cnt}")
            mob_df = st.session_state.get("mobility_results")
            if mob_df is not None and len(mob_df) > 0:
                mob_counts = mob_df["mobility"].value_counts().to_dict()
                conj = mob_counts.get("Conjugative", 0)
                if conj > 0:
                    st.markdown(f"**Mobility:** {conj} conjugative")
            outbreak = st.session_state.get("outbreak_clusters", [])
            if outbreak:
                st.markdown(f"**Outbreak clusters:** {len(outbreak)}")
            nt_res = st.session_state.get("nt_results")
            if nt_res and nt_res.get("inc_preds") is not None:
                st.markdown("**NT LLM:** enabled")
        st.divider()

    if st.button("ğŸ”„ Clear & Reset", use_container_width=True, key="sidebar_reset"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.cache_data.clear()
        st.rerun()

    if st.session_state.analysis_done:
        if st.button("ğŸ“‚ New Analysis", use_container_width=True, type="primary"):
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.cache_data.clear()
            st.rerun()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MAIN ANALYSIS PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if run_btn and uploaded_files:
    st.session_state._uploaded_files = uploaded_files
    st.session_state._inc_type = inc_type
    st.session_state._linkage_method = linkage_method
    st.session_state._use_adaptive = use_adaptive
    st.session_state._use_nt = use_nt
    st.session_state._nt_model_choice = nt_model_choice
    st.session_state._nt_device = nt_device
    progress = st.progress(0, text="Starting analysis...")

    # Step 1: Parse sequences (+ Inc group auto-detection)
    progress.progress(5, text="Parsing FASTA files & detecting Inc groups..." if inc_type == "Auto-detect"
                      else "Parsing FASTA files...")
    try:
        records = parse_uploaded_fastas(uploaded_files, inc_type)
        if len(records) < 2:
            st.error("Need at least 2 sequences for clustering.")
            st.stop()
        st.session_state.records = records
    except Exception as e:
        st.error(f"Failed to parse FASTA files: {e}")
        st.stop()

    # Step 2: K-mer vectors
    progress.progress(15, text=f"Computing 4-mer vectors for {len(records)} plasmids...")
    sequences = [r["sequence"] for r in records]
    vectors = compute_kmer_vectors(tuple(sequences), k=4)

    # Step 2b: Adaptive threshold calibration (if enabled)
    active_thresholds = PLIN_THRESHOLDS
    if use_adaptive:
        progress.progress(25, text="Calibrating adaptive thresholds from training data...")
        calibrated = calibrate_inc_thresholds()
        if calibrated:
            # Use thresholds for the dominant Inc group in the upload
            inc_counts = Counter(r["inc_type"] for r in records)
            dominant_inc = inc_counts.most_common(1)[0][0]
            if dominant_inc in calibrated:
                active_thresholds = calibrated[dominant_inc]
                st.session_state.active_thresholds = active_thresholds
                st.session_state._calibrated_all = calibrated
                st.session_state._dominant_inc = dominant_inc

    # Step 3: Clustering & pLIN assignment
    progress.progress(40, text=f"Clustering ({linkage_method} linkage) & assigning pLIN codes...")
    plin_codes, cluster_assignments, Z, dist_condensed = assign_plin_codes(
        vectors, linkage_method=linkage_method, thresholds=active_thresholds
    )
    strain_clusters = list(cluster_assignments["F"])
    st.session_state.linkage_method_used = linkage_method

    # Step 4: Build results
    progress.progress(55, text="Building results table...")
    plin_df = build_results_df(records, plin_codes, cluster_assignments)
    labels = [r["source_file"].replace(".fasta", "").replace(".fa", "").replace(".fna", "")
              for r in records]

    st.session_state.plin_df = plin_df
    st.session_state.Z = Z
    st.session_state.labels = labels
    st.session_state.plin_codes = plin_codes
    st.session_state.strain_clusters = strain_clusters
    st.session_state.cluster_assignments = cluster_assignments

    # Step 4b: Nucleotide Transformer predictions (optional)
    if use_nt and NT_AVAILABLE:
        progress.progress(56, text="Loading Nucleotide Transformer model...")
        try:
            nt_model_id = NT_MODELS.get(nt_model_choice, list(NT_MODELS.values())[0])
            tokenizer, nt_model, nt_dev = load_nt_model(nt_model_id, nt_device)

            has_inc_probe = os.path.exists(NT_INC_PROBE_PATH)
            has_amr_probe = os.path.exists(NT_AMR_PROBE_PATH)

            if not has_inc_probe and not has_amr_probe:
                st.warning(
                    "NT probes not found. Run `python train_nt_classifier.py` first to train "
                    "the classifier probes from your training data.",
                    icon="ğŸ¤–",
                )
                st.session_state.nt_results = None
            else:
                def nt_cb(pct):
                    progress.progress(int(56 + pct * 4),
                                      text=f"NT embeddings: {int(pct * 100)}%")

                nt_results = run_nt_predictions(sequences, tokenizer, nt_model, nt_dev, nt_cb)
                st.session_state.nt_results = nt_results
        except Exception as e:
            st.warning(f"Nucleotide Transformer failed: {e}. Continuing with KNN only.", icon="âš ï¸")
            st.session_state.nt_results = None

    # Step 5: AMRFinderPlus (optional)
    amr_df = pd.DataFrame()
    if run_amr and amr_binary:
        progress.progress(60, text="Running AMRFinderPlus...")

        def amr_cb(pct):
            progress.progress(int(60 + pct * 30), text=f"AMRFinderPlus: {int(pct * 100)}%")

        amr_df = run_amrfinder_on_files(uploaded_files, amr_binary, amr_db, amr_cb)

    st.session_state.amr_df = amr_df

    # Step 6: Integration
    progress.progress(90, text="Integrating results...")
    integrated_df = integrate_plin_amr(plin_df, amr_df)
    st.session_state.integrated_df = integrated_df

    # Step 7: Mobility prediction
    progress.progress(93, text="Predicting plasmid mobility...")
    mobility_results = []
    for rec in records:
        mob_class, mob_genes, mob_detail = classify_mobility(amr_df, rec["source_file"])
        mobility_results.append({
            "plasmid_id": rec["plasmid_id"],
            "mobility": mob_class,
            "mobility_genes": "; ".join(mob_genes) if mob_genes else "",
            "mobility_detail": mob_detail,
        })
    st.session_state.mobility_results = pd.DataFrame(mobility_results)

    # Step 8: Outbreak detection
    progress.progress(96, text="Scanning for outbreak clusters...")
    outbreak_clusters = detect_outbreak_clusters(plin_df, integrated_df)
    st.session_state.outbreak_clusters = outbreak_clusters

    progress.progress(100, text="Analysis complete!")
    st.session_state.analysis_done = True
    st.rerun()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  TABS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

tab_overview, tab_results, tab_clado, tab_amr, tab_epi, tab_export = st.tabs(
    ["ğŸ“‹ Overview", "ğŸ“Š Results", "ğŸŒ³ Cladogram", "ğŸ’Š AMR Analysis",
     "ğŸ”¬ Epidemiology", "ğŸ“¥ Export"]
)

# â”€â”€ TAB 1: Overview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_overview:
    st.header("pLIN â€” Plasmid Life Identification Number")
    st.markdown("""
    **pLIN** assigns each plasmid a six-position hierarchical code (`A.B.C.D.E.F`)
    based on tetranucleotide (4-mer) composition distances and single-linkage clustering.
    """)

    col1, col2 = st.columns(2)
    with col1:
        st.subheader("pLIN Hierarchy")
        thresh_data = [{"Position": b, "Level": PLIN_LEVEL_NAMES[b],
                        "Threshold": f"d \u2264 {t:.3f}", "ANI": ANI_EQUIV[b]}
                       for b, t in PLIN_THRESHOLDS.items()]
        st.dataframe(pd.DataFrame(thresh_data), use_container_width=True, hide_index=True)

    with col2:
        st.subheader("How it works")
        st.markdown("""
        1. **Upload** plasmid FASTA sequences
        2. **Auto-detect** Inc group (KNN classifier, 96% accuracy)
        3. **Compute** tetranucleotide frequency vectors (256 features)
        4. **Calculate** pairwise cosine distances
        5. **Cluster** using single-linkage hierarchical method
        6. **Cut** tree at 6 thresholds â†’ pLIN codes
        7. **Screen** for AMR genes with AMRFinderPlus *(optional)*
        """)

    if st.session_state.analysis_done:
        st.success("Analysis complete!")
        df = st.session_state.plin_df
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Plasmids", len(df))
        c2.metric("Unique pLIN Codes", df["pLIN"].nunique())
        c3.metric("Strain Clusters (F)", df["bin_F"].nunique())
        amr_count = st.session_state.integrated_df["AMR_count"].sum() if st.session_state.integrated_df is not None else 0
        c4.metric("AMR Detections", int(amr_count))

        # Show analysis parameters
        params_col1, params_col2 = st.columns(2)
        with params_col1:
            lm = st.session_state.get("linkage_method_used", "single")
            st.markdown(f"**Linkage method:** `{lm}`")
        with params_col2:
            at = st.session_state.get("active_thresholds")
            if at and at != PLIN_THRESHOLDS:
                dom_inc = st.session_state.get("_dominant_inc", "?")
                st.markdown(f"**Adaptive thresholds:** calibrated for **{dom_inc}**")
            else:
                st.markdown("**Thresholds:** default (fixed)")

        # Show adaptive threshold comparison if used
        if st.session_state.get("active_thresholds") and st.session_state.active_thresholds != PLIN_THRESHOLDS:
            with st.expander("Adaptive vs Default Thresholds"):
                at = st.session_state.active_thresholds
                comp_rows = []
                for level in "ABCDEF":
                    comp_rows.append({
                        "Level": f"{level} ({PLIN_LEVEL_NAMES[level]})",
                        "Default": f"{PLIN_THRESHOLDS[level]:.4f}",
                        "Adaptive": f"{at[level]:.6f}",
                        "Change": f"{((at[level] - PLIN_THRESHOLDS[level]) / PLIN_THRESHOLDS[level] * 100):+.1f}%",
                    })
                st.dataframe(pd.DataFrame(comp_rows), use_container_width=True, hide_index=True)

        # Inc group auto-detection summary
        if "inc_confidence" in df.columns:
            st.subheader("Inc Group Auto-Detection")
            inc_summary = df.groupby("inc_type").agg(
                count=("plasmid_id", "count"),
                avg_confidence=("inc_confidence", "mean"),
                min_confidence=("inc_confidence", "min"),
            ).reset_index().rename(columns={
                "inc_type": "Inc Group",
                "count": "Plasmids",
                "avg_confidence": "Avg Confidence",
                "min_confidence": "Min Confidence",
            })
            inc_summary["Avg Confidence"] = inc_summary["Avg Confidence"].round(4)
            inc_summary["Min Confidence"] = inc_summary["Min Confidence"].round(4)
            st.dataframe(inc_summary, use_container_width=True, hide_index=True)

            # Warn about mixed Inc groups
            n_inc_groups = df["inc_type"].nunique()
            if n_inc_groups > 1:
                st.info(
                    f"**{n_inc_groups} Inc groups detected** in your upload. "
                    "pLIN clustering is computed across all plasmids together. "
                    "For within-group comparisons, upload files from a single Inc group."
                )

        # NT prediction comparison (if available)
        nt_res = st.session_state.get("nt_results")
        if nt_res and nt_res.get("inc_preds") is not None:
            st.subheader("Nucleotide Transformer LLM Predictions")
            nt_inc_preds = nt_res["inc_preds"]
            knn_preds = df["inc_type"].tolist()

            # Agreement rate
            agree = sum(1 for k, n in zip(knn_preds, nt_inc_preds) if k == n)
            total = len(knn_preds)
            agreement_pct = agree / total * 100 if total > 0 else 0

            nc1, nc2, nc3 = st.columns(3)
            nc1.metric("KNN vs NT Agreement", f"{agreement_pct:.1f}%")
            if nt_res.get("inc_cv_accuracy"):
                nc2.metric("NT Probe CV Accuracy", f"{nt_res['inc_cv_accuracy']:.1%}")
            nc3.metric("NT Embedding Dim", nt_res["embeddings"].shape[1])

            # Show disagreements
            disagreements = []
            for i, (k, n) in enumerate(zip(knn_preds, nt_inc_preds)):
                if k != n:
                    pid = df["plasmid_id"].iloc[i] if i < len(df) else f"seq_{i}"
                    disagreements.append({"Plasmid": pid, "KNN": k, "NT": n})
            if disagreements:
                with st.expander(f"KNN vs NT Disagreements ({len(disagreements)})"):
                    st.dataframe(pd.DataFrame(disagreements),
                                 use_container_width=True, hide_index=True)
            else:
                st.success("KNN and Nucleotide Transformer predictions agree on all plasmids.")

            # NT AMR predictions
            if nt_res.get("amr_preds") is not None:
                amr_classes = nt_res["amr_classes"]
                amr_preds = nt_res["amr_preds"]
                pos_counts = amr_preds.sum(axis=0)
                detected = [(c, int(n)) for c, n in zip(amr_classes, pos_counts) if n > 0]
                if detected:
                    st.markdown("**NT-predicted AMR drug classes:**")
                    amr_pred_df = pd.DataFrame(detected, columns=["Drug Class", "Plasmids"])
                    amr_pred_df = amr_pred_df.sort_values("Plasmids", ascending=False)
                    st.dataframe(amr_pred_df, use_container_width=True, hide_index=True)


# â”€â”€ TAB 2: Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_results:
    if not st.session_state.analysis_done:
        st.info("Run analysis first to see results.")
    else:
        st.header("pLIN Assignments")

        df = st.session_state.integrated_df
        has_inc_conf = "inc_confidence" in st.session_state.plin_df.columns

        # Merge mobility data if available
        mob_df = st.session_state.get("mobility_results")
        if mob_df is not None and len(mob_df) > 0:
            if "mobility" not in df.columns:
                df = df.merge(mob_df[["plasmid_id", "mobility", "mobility_genes"]], on="plasmid_id", how="left")

        # Merge NT predictions if available
        nt_res = st.session_state.get("nt_results")
        if nt_res and nt_res.get("inc_preds") is not None and "nt_inc_type" not in df.columns:
            nt_inc_preds = nt_res["inc_preds"]
            if len(nt_inc_preds) == len(df):
                df["nt_inc_type"] = nt_inc_preds

        if df is not None and "AMR_genes" in df.columns:
            display_cols = ["plasmid_id", "inc_type"]
            if "nt_inc_type" in df.columns:
                display_cols.append("nt_inc_type")
            if has_inc_conf:
                display_cols.append("inc_confidence")
            display_cols += ["source_file", "length_bp", "pLIN"]
            if "mobility" in df.columns:
                display_cols.append("mobility")
            display_cols += ["AMR_count", "STRESS_count", "AMR_genes", "AMR_classes"]
            if "mobility_genes" in df.columns:
                display_cols.append("mobility_genes")
            # merge inc_confidence from plin_df if not already present
            if has_inc_conf and "inc_confidence" not in df.columns:
                df = df.merge(
                    st.session_state.plin_df[["plasmid_id", "inc_confidence"]],
                    on="plasmid_id", how="left",
                )
            display_cols = [c for c in display_cols if c in df.columns]
        else:
            df = st.session_state.plin_df
            if mob_df is not None and len(mob_df) > 0 and "mobility" not in df.columns:
                df = df.merge(mob_df[["plasmid_id", "mobility", "mobility_genes"]], on="plasmid_id", how="left")
            display_cols = ["plasmid_id", "inc_type"]
            if "nt_inc_type" in df.columns:
                display_cols.append("nt_inc_type")
            if has_inc_conf:
                display_cols.append("inc_confidence")
            display_cols += ["source_file", "length_bp", "pLIN"]
            if "mobility" in df.columns:
                display_cols.append("mobility")
            display_cols += ["bin_A", "bin_B", "bin_C", "bin_D", "bin_E", "bin_F"]

        # Search filter
        search = st.text_input("ğŸ” Search plasmid ID, pLIN code, or Inc group", "")
        if search:
            mask = (
                df["plasmid_id"].str.contains(search, case=False, na=False) |
                df["pLIN"].str.contains(search, case=False, na=False) |
                df["inc_type"].str.contains(search, case=False, na=False)
            )
            df_display = df[mask][display_cols]
        else:
            df_display = df[display_cols]

        st.dataframe(df_display, use_container_width=True, hide_index=True)

        # Summary stats
        with st.expander("Summary Statistics"):
            c1, c2 = st.columns(2)
            with c1:
                st.write("**pLIN Code Distribution**")
                st.dataframe(df["pLIN"].value_counts().reset_index().rename(
                    columns={"index": "pLIN", "pLIN": "pLIN Code", "count": "Count"}),
                    use_container_width=True, hide_index=True)
            with c2:
                st.write("**Sequence Length Statistics**")
                st.write(df["length_bp"].describe().to_frame("Value"))

            if has_inc_conf:
                st.write("**Per-Plasmid Inc Group Classification**")
                inc_detail = st.session_state.plin_df[["plasmid_id", "inc_type", "inc_confidence"]].copy()
                inc_detail = inc_detail.sort_values("inc_confidence", ascending=True)
                st.dataframe(inc_detail, use_container_width=True, hide_index=True)


# â”€â”€ TAB 3: Cladogram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_clado:
    if not st.session_state.analysis_done:
        st.info("Run analysis first to see cladograms.")
    else:
        st.header("Cladogram Visualization")

        viz_type = st.radio("Visualization type", ["Rectangular", "Circular", "Heatmap", "AMR Annotated"],
                            horizontal=True)

        Z = st.session_state.Z
        labels = st.session_state.labels
        plin_codes = st.session_state.plin_codes
        strain_clusters = st.session_state.strain_clusters

        with st.spinner("Generating cladogram..."):
            if viz_type == "Rectangular":
                fig = plot_rectangular_cladogram(Z, labels, plin_codes, strain_clusters)
            elif viz_type == "Circular":
                fig = plot_circular_cladogram(Z, labels, plin_codes, strain_clusters)
            elif viz_type == "Heatmap":
                fig = plot_cladogram_heatmap(Z, labels, plin_codes,
                                            st.session_state.cluster_assignments,
                                            st.session_state.records)
            else:  # AMR Annotated
                amr_df = st.session_state.amr_df
                if amr_df is not None and len(amr_df) > 0:
                    fig = plot_cladogram_amr(Z, labels, plin_codes, strain_clusters,
                                            amr_df, st.session_state.records)
                else:
                    st.warning("No AMR data available. Run analysis with AMRFinderPlus enabled.")
                    fig = plot_rectangular_cladogram(Z, labels, plin_codes, strain_clusters)

            st.pyplot(fig, use_container_width=True)

        # Download buttons
        col1, col2 = st.columns(2)
        with col1:
            st.download_button("ğŸ“¥ Download PNG", fig_to_bytes(fig, "png"),
                               f"pLIN_cladogram_{viz_type.lower()}.png", "image/png")
        with col2:
            st.download_button("ğŸ“¥ Download PDF", fig_to_bytes(fig, "pdf"),
                               f"pLIN_cladogram_{viz_type.lower()}.pdf", "application/pdf")
        plt.close(fig)


# â”€â”€ TAB 4: AMR Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_amr:
    if not st.session_state.analysis_done:
        st.info("Run analysis first to see AMR results.")
    elif st.session_state.amr_df is None or len(st.session_state.amr_df) == 0:
        st.warning("No AMR data. Run a new analysis with AMRFinderPlus enabled.")
    else:
        st.header("AMR Gene Analysis")
        amr_df = st.session_state.amr_df
        integrated = st.session_state.integrated_df

        # Metrics
        c1, c2, c3, c4 = st.columns(4)
        amr_only = amr_df[amr_df["Type"] == "AMR"] if "Type" in amr_df.columns else pd.DataFrame()
        stress_only = amr_df[amr_df["Type"] == "STRESS"] if "Type" in amr_df.columns else pd.DataFrame()
        c1.metric("Total Detections", len(amr_df))
        c2.metric("AMR Genes", len(amr_only))
        c3.metric("Stress Genes", len(stress_only))
        c4.metric("Plasmids with AMR", int((integrated["AMR_count"] > 0).sum()))

        # Interactive gene prevalence chart
        if len(amr_only) > 0:
            col1, col2 = st.columns(2)
            with col1:
                gene_freq = amr_only.groupby("Element symbol")["source_file"].nunique().sort_values(ascending=False)
                fig_bar = px.bar(
                    x=gene_freq.values, y=gene_freq.index,
                    orientation="h", title="AMR Gene Prevalence (# Plasmids)",
                    labels={"x": "Number of Plasmids", "y": "Gene"},
                    color_discrete_sequence=["#E53935"],
                )
                fig_bar.update_layout(height=400, yaxis=dict(autorange="reversed"))
                st.plotly_chart(fig_bar, use_container_width=True)

            with col2:
                if "Class" in amr_only.columns:
                    class_counts = amr_only["Class"].value_counts()
                    fig_pie = px.pie(
                        values=class_counts.values, names=class_counts.index,
                        title="AMR Drug Classes",
                        color_discrete_sequence=px.colors.qualitative.Set2,
                    )
                    fig_pie.update_layout(height=400)
                    st.plotly_chart(fig_pie, use_container_width=True)

        # Critical gene alerts
        if len(amr_only) > 0:
            critical_genes = {
                "Carbapenemases": ["blaKPC", "blaNDM", "blaOXA-48", "blaVIM", "blaIMP"],
                "ESBLs": ["blaCTX-M", "blaSHV-12", "blaTEM"],
                "Colistin resistance": ["mcr"],
            }
            alerts = []
            for category, prefixes in critical_genes.items():
                for prefix in prefixes:
                    matches = amr_only[amr_only["Element symbol"].str.startswith(prefix)]
                    if len(matches) > 0:
                        genes = matches["Element symbol"].unique()
                        n_plasmids = matches["source_file"].nunique()
                        alerts.append(f"**{category}**: {', '.join(genes)} detected in {n_plasmids} plasmid(s)")
            if alerts:
                st.warning("âš ï¸ **Critical Resistance Genes Detected**\n\n" + "\n\n".join(alerts))

        # Full AMR table
        with st.expander("Full AMR Detection Table"):
            st.dataframe(amr_df, use_container_width=True, hide_index=True)


# â”€â”€ TAB 5: Epidemiology â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_epi:
    if not st.session_state.analysis_done:
        st.info("Run analysis first to see epidemiological insights.")
    else:
        st.header("Epidemiological Analysis")

        epi_col1, epi_col2 = st.columns(2)

        # â”€â”€â”€ Mobility Prediction â”€â”€â”€
        with epi_col1:
            st.subheader("Plasmid Mobility Prediction")
            mob_df = st.session_state.get("mobility_results")
            if mob_df is not None and len(mob_df) > 0:
                mob_counts = mob_df["mobility"].value_counts()
                # Color-coded metrics
                mob_colors = {"Conjugative": "#E53935", "Mobilizable": "#FB8C00",
                              "Non-mobilizable": "#43A047", "Unknown": "#9E9E9E"}
                mc1, mc2, mc3 = st.columns(3)
                mc1.metric("Conjugative", int(mob_counts.get("Conjugative", 0)))
                mc2.metric("Mobilizable", int(mob_counts.get("Mobilizable", 0)))
                mc3.metric("Non-mobilizable", int(mob_counts.get("Non-mobilizable", 0)))

                # Pie chart
                fig_mob = px.pie(
                    values=mob_counts.values, names=mob_counts.index,
                    title="Mobility Classification",
                    color=mob_counts.index,
                    color_discrete_map=mob_colors,
                )
                fig_mob.update_layout(height=350)
                st.plotly_chart(fig_mob, use_container_width=True)

                # Detail table
                with st.expander("Mobility Details"):
                    st.dataframe(mob_df, use_container_width=True, hide_index=True)

                if int(mob_counts.get("Conjugative", 0)) > 0:
                    conj_plasmids = mob_df[mob_df["mobility"] == "Conjugative"]["plasmid_id"].tolist()
                    st.warning(
                        f"**{len(conj_plasmids)} conjugative plasmid(s) detected** â€” "
                        "these can self-transfer to other bacteria via conjugation, "
                        "posing higher risk for AMR dissemination."
                    )
            else:
                st.info("No mobility data. Run analysis with AMRFinderPlus enabled.")

        # â”€â”€â”€ Outbreak Detection â”€â”€â”€
        with epi_col2:
            st.subheader("Outbreak / Clone Detection")
            outbreak_clusters = st.session_state.get("outbreak_clusters", [])

            if outbreak_clusters:
                st.metric("Suspected Outbreak Clusters", len(outbreak_clusters))

                for i, cluster in enumerate(outbreak_clusters):
                    risk_color = "ğŸ”´" if cluster["risk_level"] == "HIGH" else "ğŸŸ¡"
                    with st.expander(
                        f"{risk_color} Cluster {i+1}: pLIN {cluster['pLIN']} "
                        f"({cluster['n_plasmids']} plasmids, {cluster['n_amr_genes']} AMR genes)"
                    ):
                        st.markdown(f"**Risk level:** {cluster['risk_level']}")
                        st.markdown(f"**Strain cluster (F):** {cluster['strain_cluster']}")
                        st.markdown(f"**Shared AMR genes:** {', '.join(cluster['amr_genes'])}")
                        st.markdown(f"**Plasmids:**")
                        for p in cluster["plasmids"]:
                            st.markdown(f"  - `{p}`")

                if any(c["risk_level"] == "HIGH" for c in outbreak_clusters):
                    st.error(
                        "**HIGH-RISK outbreak cluster(s) detected.** "
                        "Plasmids sharing identical strain-level pLIN codes AND "
                        "the same AMR resistance profile may indicate clonal spread."
                    )
            else:
                st.info(
                    "No outbreak clusters detected. Outbreak detection flags groups of "
                    "plasmids sharing the same pLIN strain code (F-level) AND identical "
                    "AMR resistance profiles."
                )

        # â”€â”€â”€ Risk Summary â”€â”€â”€
        st.divider()
        st.subheader("Dissemination Risk Summary")

        integrated = st.session_state.integrated_df
        mob_df = st.session_state.get("mobility_results")

        if integrated is not None and mob_df is not None and len(mob_df) > 0:
            risk_df = integrated[["plasmid_id", "pLIN", "inc_type", "AMR_count"]].merge(
                mob_df[["plasmid_id", "mobility"]], on="plasmid_id", how="left"
            )

            # High risk: conjugative + AMR genes
            high_risk = risk_df[(risk_df["mobility"] == "Conjugative") & (risk_df["AMR_count"] > 0)]
            moderate_risk = risk_df[(risk_df["mobility"] == "Mobilizable") & (risk_df["AMR_count"] > 0)]

            rc1, rc2, rc3 = st.columns(3)
            rc1.metric("High Risk", len(high_risk),
                       help="Conjugative plasmids carrying AMR genes")
            rc2.metric("Moderate Risk", len(moderate_risk),
                       help="Mobilizable plasmids carrying AMR genes")
            rc3.metric("Lower Risk", len(risk_df) - len(high_risk) - len(moderate_risk),
                       help="Non-mobilizable or no AMR genes")

            if len(high_risk) > 0:
                st.warning(
                    f"**{len(high_risk)} high-risk plasmid(s):** conjugative AND carrying AMR genes. "
                    "These represent the highest priority for infection control surveillance."
                )
                st.dataframe(high_risk[["plasmid_id", "pLIN", "inc_type", "AMR_count", "mobility"]],
                             use_container_width=True, hide_index=True)


# â”€â”€ TAB 6: Export â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab_export:
    if not st.session_state.analysis_done:
        st.info("Run analysis first to export results.")
    else:
        st.header("Export Results")

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Tables")
            # pLIN results
            plin_csv = st.session_state.plin_df.to_csv(sep="\t", index=False).encode()
            st.download_button("ğŸ“¥ pLIN Assignments (TSV)", plin_csv,
                               "pLIN_assignments.tsv", "text/tab-separated-values")

            # Integrated results
            if st.session_state.integrated_df is not None:
                int_csv = st.session_state.integrated_df.to_csv(sep="\t", index=False).encode()
                st.download_button("ğŸ“¥ Integrated pLIN + AMR (TSV)", int_csv,
                                   "pLIN_AMR_integrated.tsv", "text/tab-separated-values")

            # Raw AMR
            if st.session_state.amr_df is not None and len(st.session_state.amr_df) > 0:
                amr_csv = st.session_state.amr_df.to_csv(sep="\t", index=False).encode()
                st.download_button("ğŸ“¥ AMR Detections (TSV)", amr_csv,
                                   "amrfinder_results.tsv", "text/tab-separated-values")

            # Mobility results
            mob_df = st.session_state.get("mobility_results")
            if mob_df is not None and len(mob_df) > 0:
                mob_csv = mob_df.to_csv(sep="\t", index=False).encode()
                st.download_button("ğŸ“¥ Mobility Predictions (TSV)", mob_csv,
                                   "mobility_predictions.tsv", "text/tab-separated-values")

        with col2:
            st.subheader("Figures")
            Z = st.session_state.Z
            labels = st.session_state.labels
            plin_codes = st.session_state.plin_codes
            strain_clusters = st.session_state.strain_clusters

            for name, func, args in [
                ("Rectangular Cladogram", plot_rectangular_cladogram,
                 (Z, labels, plin_codes, strain_clusters)),
                ("Circular Cladogram", plot_circular_cladogram,
                 (Z, labels, plin_codes, strain_clusters)),
            ]:
                fig = func(*args)
                st.download_button(f"ğŸ“¥ {name} (PNG)", fig_to_bytes(fig),
                                   f"{name.lower().replace(' ', '_')}.png", "image/png")
                plt.close(fig)

            # AMR cladogram if available
            if st.session_state.amr_df is not None and len(st.session_state.amr_df) > 0:
                fig = plot_cladogram_amr(Z, labels, plin_codes, strain_clusters,
                                        st.session_state.amr_df, st.session_state.records)
                st.download_button("ğŸ“¥ AMR Cladogram (PNG)", fig_to_bytes(fig),
                                   "cladogram_amr.png", "image/png")
                plt.close(fig)

        st.divider()

        # ZIP bundle
        st.subheader("Download All (ZIP)")
        if st.button("ğŸ“¦ Generate ZIP Bundle"):
            with st.spinner("Creating ZIP..."):
                zip_buf = io.BytesIO()
                with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as zf:
                    zf.writestr("pLIN_assignments.tsv",
                                st.session_state.plin_df.to_csv(sep="\t", index=False))
                    if st.session_state.integrated_df is not None:
                        zf.writestr("pLIN_AMR_integrated.tsv",
                                    st.session_state.integrated_df.to_csv(sep="\t", index=False))
                    if st.session_state.amr_df is not None and len(st.session_state.amr_df) > 0:
                        zf.writestr("amrfinder_results.tsv",
                                    st.session_state.amr_df.to_csv(sep="\t", index=False))
                    mob_df = st.session_state.get("mobility_results")
                    if mob_df is not None and len(mob_df) > 0:
                        zf.writestr("mobility_predictions.tsv",
                                    mob_df.to_csv(sep="\t", index=False))
                    outbreak = st.session_state.get("outbreak_clusters", [])
                    if outbreak:
                        import json
                        zf.writestr("outbreak_clusters.json",
                                    json.dumps(outbreak, indent=2))
                    # NT predictions
                    nt_res = st.session_state.get("nt_results")
                    if nt_res and nt_res.get("inc_preds") is not None:
                        nt_df = pd.DataFrame({
                            "plasmid_id": st.session_state.plin_df["plasmid_id"],
                            "knn_inc_type": st.session_state.plin_df["inc_type"],
                            "nt_inc_type": nt_res["inc_preds"],
                        })
                        zf.writestr("nt_predictions.tsv",
                                    nt_df.to_csv(sep="\t", index=False))
                    for name, func, args in [
                        ("cladogram_rectangular", plot_rectangular_cladogram,
                         (Z, labels, plin_codes, strain_clusters)),
                        ("cladogram_circular", plot_circular_cladogram,
                         (Z, labels, plin_codes, strain_clusters)),
                    ]:
                        fig = func(*args)
                        zf.writestr(f"{name}.png", fig_to_bytes(fig))
                        zf.writestr(f"{name}.pdf", fig_to_bytes(fig, "pdf"))
                        plt.close(fig)

                    # AMR cladogram in ZIP
                    if st.session_state.amr_df is not None and len(st.session_state.amr_df) > 0:
                        fig = plot_cladogram_amr(Z, labels, plin_codes, strain_clusters,
                                                st.session_state.amr_df, st.session_state.records)
                        zf.writestr("cladogram_amr.png", fig_to_bytes(fig))
                        zf.writestr("cladogram_amr.pdf", fig_to_bytes(fig, "pdf"))
                        plt.close(fig)

                zip_buf.seek(0)
                st.download_button("ğŸ“¥ Download ZIP", zip_buf.getvalue(),
                                   "pLIN_results.zip", "application/zip")
